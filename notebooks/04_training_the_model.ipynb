{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a472a1a8",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "In this notebook, we will use the engineered features to train a machine learning model to predict departure delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4acf8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing this cell does some magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "645db04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\Personal_Things\\My Website\\My website HTML\\backend\\supplychainAPI\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb097a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a035ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from models.src.LightGBM import LightGBM\n",
    "from features.src.feature_engineering_depDelay import FeatureEngineeringDepDelay\n",
    "from openmeteo_api.src.openmeteoapi.WeatherData import Weather\n",
    "from openmeteo_api.src.openmeteoapi.APICaller import OpenMeteoAPICaller\n",
    "from aeromarket_api.src.aeroapi_market.APICaller import APICaller\n",
    "from aeromarket_api.src.aeroapi_market.Flights import Flights\n",
    "from FlightWeather.src.FlightWeather import FlightWeather\n",
    "from models.src.catboost import CatBoost\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from models.src.XGBoast import XGBoost\n",
    "from models.src.RandomForest import RandomForest\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cffc1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_parquet('./data/sample_df_v3.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b2a183",
   "metadata": {},
   "source": [
    "## Handeling Missing Data\n",
    "\n",
    "Before we train any model, it is a good idea to handle missing data earlier so we do not have bias in our prediction. Dropping missing data blindly could introduce some bias in our data, so it would be a better idea to decide how we handle them earlier. Lets first graph the missing data of the target variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2da0f1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>source</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>total_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DepDelayMinutes</td>\n",
       "      <td>sample_df</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            column     source  missing_count  missing_%  total_rows\n",
       "0  DepDelayMinutes  sample_df              4      0.004      100000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "s = sample_df[\"DepDelayMinutes\"]\n",
    "rows.append({\n",
    "    \"column\": \"DepDelayMinutes\",\n",
    "    \"source\": \"sample_df\",\n",
    "    \"missing_count\": int(s.isna().sum()),\n",
    "    \"missing_%\": float(s.isna().mean() * 100),\n",
    "    \"total_rows\": int(len(s)),\n",
    "})\n",
    "\n",
    "missing_summary = pd.DataFrame(rows).sort_values([\"missing_%\", \"missing_count\"], ascending=False).reset_index(drop=True)\n",
    "display(missing_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62b9bd",
   "metadata": {},
   "source": [
    "We can see here that only 0.004% of the target variable `DepDelayMinutes` is missing. We can also check which rows are missing this data to see if there is any pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "576b4e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing DepDelayMinutes: 4 / 100000 (0.0040%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IATA_Code_Operating_Airline</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>dep_date_local</th>\n",
       "      <th>arr_datetime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>DepDelayMinutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9E</td>\n",
       "      <td>LGA</td>\n",
       "      <td>GSO</td>\n",
       "      <td>2018-04-30 15:00:00</td>\n",
       "      <td>2018-04-30 17:00:00</td>\n",
       "      <td>461.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9E</td>\n",
       "      <td>RDU</td>\n",
       "      <td>LGA</td>\n",
       "      <td>2018-04-22 17:00:00</td>\n",
       "      <td>2018-04-22 18:00:00</td>\n",
       "      <td>431.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9E</td>\n",
       "      <td>JFK</td>\n",
       "      <td>RIC</td>\n",
       "      <td>2018-04-27 19:00:00</td>\n",
       "      <td>2018-04-27 21:00:00</td>\n",
       "      <td>288.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9E</td>\n",
       "      <td>JFK</td>\n",
       "      <td>RIC</td>\n",
       "      <td>2018-01-26 14:00:00</td>\n",
       "      <td>2018-01-26 16:00:00</td>\n",
       "      <td>288.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IATA_Code_Operating_Airline Origin Dest      dep_date_local  \\\n",
       "0                          9E    LGA  GSO 2018-04-30 15:00:00   \n",
       "1                          9E    RDU  LGA 2018-04-22 17:00:00   \n",
       "2                          9E    JFK  RIC 2018-04-27 19:00:00   \n",
       "3                          9E    JFK  RIC 2018-01-26 14:00:00   \n",
       "\n",
       "         arr_datetime  Distance  CRSElapsedTime  DepDelayMinutes  \n",
       "0 2018-04-30 17:00:00     461.0           113.0              NaN  \n",
       "1 2018-04-22 18:00:00     431.0           109.0              NaN  \n",
       "2 2018-04-27 21:00:00     288.0           103.0              NaN  \n",
       "3 2018-01-26 16:00:00     288.0           104.0              NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_mask = sample_df[\"DepDelayMinutes\"].isna()\n",
    "n_missing = int(missing_mask.sum())\n",
    "n_total = int(len(sample_df))\n",
    "print(f\"Missing DepDelayMinutes: {n_missing} / {n_total} ({(n_missing/n_total)*100:.4f}%)\")\n",
    "\n",
    "key_cols = [c for c in [\"IATA_Code_Operating_Airline\", \"Origin\", \"Dest\", \"dep_date_local\", \"arr_datetime\", \"Distance\", \"CRSElapsedTime\"] if c in sample_df.columns]\n",
    "if n_missing > 0:\n",
    "    display(sample_df.loc[missing_mask, key_cols + [\"DepDelayMinutes\"]].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a01d8",
   "metadata": {},
   "source": [
    "As we can see here, all the missing values come from flights operated by \"9E\" airline. Depending on the amount of missing data and the importance of the feature, we can decide to either drop these rows or impute them with some value. In this case, since the amount of missing data is very small, we can safely drop these rows without introducing significant bias in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "231e8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df[~missing_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8b3676",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "As a first step, we will load the sample data and apply the feature engineering pipeline to prepare the data for modeling, and split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07481311",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df = FeatureEngineeringDepDelay(sample_df).engineer_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262b16c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IATA_Code_Operating_Airline</th>\n",
       "      <th>Distance</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>dep_snowfall</th>\n",
       "      <th>dep_rain</th>\n",
       "      <th>dep_precipitation</th>\n",
       "      <th>dep_wind_speed_10m</th>\n",
       "      <th>dep_wind_gusts_10m</th>\n",
       "      <th>dep_cloud_cover_low</th>\n",
       "      <th>dep_cloud_cover</th>\n",
       "      <th>...</th>\n",
       "      <th>abs_apparent_temperature_delta</th>\n",
       "      <th>humidity_delta</th>\n",
       "      <th>abs_humidity_delta</th>\n",
       "      <th>pressure_delta</th>\n",
       "      <th>abs_pressure_delta</th>\n",
       "      <th>cloud_cover_delta</th>\n",
       "      <th>abs_cloud_cover_delta</th>\n",
       "      <th>dep_gust_factor</th>\n",
       "      <th>arr_gust_factor</th>\n",
       "      <th>congestion_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AS</td>\n",
       "      <td>605.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.725354</td>\n",
       "      <td>7.920000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.520615</td>\n",
       "      <td>2.279617</td>\n",
       "      <td>2.279617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.177633</td>\n",
       "      <td>2.198523</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UA</td>\n",
       "      <td>589.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.334974</td>\n",
       "      <td>12.599999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.553886</td>\n",
       "      <td>41.920712</td>\n",
       "      <td>41.920712</td>\n",
       "      <td>5.800049</td>\n",
       "      <td>5.800049</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.906591</td>\n",
       "      <td>2.796868</td>\n",
       "      <td>-66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UA</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.708391</td>\n",
       "      <td>20.160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033024</td>\n",
       "      <td>-44.060558</td>\n",
       "      <td>44.060558</td>\n",
       "      <td>-7.700012</td>\n",
       "      <td>7.700012</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.470632</td>\n",
       "      <td>2.687936</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZW</td>\n",
       "      <td>632.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.964998</td>\n",
       "      <td>33.839996</td>\n",
       "      <td>43.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.528877</td>\n",
       "      <td>24.500969</td>\n",
       "      <td>24.500969</td>\n",
       "      <td>-10.800049</td>\n",
       "      <td>10.800049</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.610104</td>\n",
       "      <td>1.778373</td>\n",
       "      <td>-73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OO</td>\n",
       "      <td>282.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.484318</td>\n",
       "      <td>16.199999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.453232</td>\n",
       "      <td>-47.497303</td>\n",
       "      <td>47.497303</td>\n",
       "      <td>-0.400024</td>\n",
       "      <td>0.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.914103</td>\n",
       "      <td>2.669635</td>\n",
       "      <td>-38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  IATA_Code_Operating_Airline  Distance  CRSElapsedTime  dep_snowfall  \\\n",
       "0                          AS     605.0           115.0           0.0   \n",
       "1                          UA     589.0           116.0           0.0   \n",
       "2                          UA    1222.0           176.0           0.0   \n",
       "3                          ZW     632.0           140.0           0.0   \n",
       "4                          OO     282.0            89.0           0.0   \n",
       "\n",
       "   dep_rain  dep_precipitation  dep_wind_speed_10m  dep_wind_gusts_10m  \\\n",
       "0       0.0                0.0            6.725354            7.920000   \n",
       "1       0.0                0.0            4.334974           12.599999   \n",
       "2       0.0                0.0           13.708391           20.160000   \n",
       "3       0.0                0.0           12.964998           33.839996   \n",
       "4       0.0                0.0            1.484318           16.199999   \n",
       "\n",
       "   dep_cloud_cover_low  dep_cloud_cover  ...  abs_apparent_temperature_delta  \\\n",
       "0                  0.0              0.0  ...                        5.520615   \n",
       "1                  0.0              0.0  ...                        9.553886   \n",
       "2                  0.0             56.0  ...                        0.033024   \n",
       "3                 43.0             51.0  ...                        2.528877   \n",
       "4                  0.0              0.0  ...                       12.453232   \n",
       "\n",
       "   humidity_delta  abs_humidity_delta  pressure_delta  abs_pressure_delta  \\\n",
       "0        2.279617            2.279617        1.000000            1.000000   \n",
       "1       41.920712           41.920712        5.800049            5.800049   \n",
       "2      -44.060558           44.060558       -7.700012            7.700012   \n",
       "3       24.500969           24.500969      -10.800049           10.800049   \n",
       "4      -47.497303           47.497303       -0.400024            0.400024   \n",
       "\n",
       "   cloud_cover_delta  abs_cloud_cover_delta  dep_gust_factor  arr_gust_factor  \\\n",
       "0                0.0                    0.0         1.177633         2.198523   \n",
       "1             -100.0                  100.0         2.906591         2.796868   \n",
       "2              -40.0                   40.0         1.470632         2.687936   \n",
       "3              -27.0                   27.0         2.610104         1.778373   \n",
       "4                0.0                    0.0        10.914103         2.669635   \n",
       "\n",
       "   congestion_delta  \n",
       "0              11.0  \n",
       "1             -66.0  \n",
       "2               6.0  \n",
       "3             -73.0  \n",
       "4             -38.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f9e719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 79996\n",
      "Testing samples: 20000\n"
     ]
    }
   ],
   "source": [
    "target_col = \"log1p_DepDelayMinutes\"\n",
    "X = engineered_df.drop(columns=[target_col])\n",
    "y = engineered_df[target_col]\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "\n",
    "for c in cat_cols:\n",
    "  X[c] = X[c].astype(\"category\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e78e634",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "As a baseline, we will first train a linear regression model. This will help us understand how well a simple model performs on this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3a2e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['IATA_Code_Operating_Airline', 'route']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = X_train.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "num_cols = X_train.select_dtypes(exclude=[\"object\", \"category\"]).columns\n",
    "print(f\"Categorical columns: {cat_cols.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2283055",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"lr\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec1d118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56435ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b596f74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR RMSE: 1.447590790367504\n",
      "LR R²: 0.10423253009445532\n"
     ]
    }
   ],
   "source": [
    "mse_lr = mean_squared_error(y_test, y_pred)\n",
    "rmse_lr = mse_lr**0.5\n",
    "r2_lr = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"LR RMSE:\", rmse_lr)\n",
    "print(\"LR R²:\", r2_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aaf737",
   "metadata": {},
   "source": [
    "These results basically say the linear regression baseline isn’t doing much yet.\n",
    "\n",
    "- **MSE: ~2.09** is the average squared error on our target. Note: our target is `log1p_DepDelayMinutes`, so this MSE is on the *log1p(minutes)* scale (not minutes).\n",
    "- A more intuitive version is **RMSE**: $\\sqrt{2.09} \\approx 1.45$ (still on the log1p scale).\n",
    "- **$R^2: ~0.09$** means the model only explains about **9% of the variance** in the test set. In other words: it’s only slightly better than predicting a constant delay for every flight.\n",
    "\n",
    "So: this is a solid “baseline check”, but it’s a sign we’ll probably need a more flexible model (like LightGBM) to capture the non-linear patterns in delays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2d9e3",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "\n",
    "Now that we’ve got a baseline with linear regression, we can switch to **LightGBM**.\n",
    "\n",
    "LightGBM is a gradient-boosted decision tree model (basically: lots of small trees added together, where each new tree tries to fix the mistakes from the previous ones). The nice part for this problem is that it can pick up **non‑linear relationships** and **feature interactions** that a simple linear model will usually miss.\n",
    "\n",
    "So the goal here isn’t to “perfectly tune” it yet — it’s to see if a stronger model can capture more signal in the engineered features and improve our metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e46ba9",
   "metadata": {},
   "source": [
    "In our LightGBM class, we have set up the model with some basic parameters. We will train the model on the training set and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03fae26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] LightGBM - LightGBM model initialized with parameters: {'objective': 'regression', 'metric': 'rmse', 'learning_rate': 0.05, 'num_leaves': 31, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'seed': 42, 'boosting_type': 'gbdt', 'verbose': -1, 'max_depth': -1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'min_data_in_leaf': 20}\n",
      "[INFO] LightGBM - Starting model training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttrain's rmse: 1.4092 + 0.000964394\tvalid's rmse: 1.42992 + 0.00829368\n",
      "[100]\ttrain's rmse: 1.37794 + 0.000965766\tvalid's rmse: 1.41863 + 0.00862381\n",
      "[150]\ttrain's rmse: 1.35657 + 0.00110601\tvalid's rmse: 1.41551 + 0.00914164\n",
      "[200]\ttrain's rmse: 1.33872 + 0.00128133\tvalid's rmse: 1.41422 + 0.00913825\n",
      "[250]\ttrain's rmse: 1.32256 + 0.00123971\tvalid's rmse: 1.41379 + 0.0093588\n",
      "[300]\ttrain's rmse: 1.30744 + 0.00114341\tvalid's rmse: 1.41333 + 0.00960345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] LightGBM - Best iteration from CV: 304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[304]\ttrain's rmse: 1.30632 + 0.00112015\tvalid's rmse: 1.41326 + 0.00961865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] LightGBM - Model training completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.src.LightGBM.LightGBM at 0x1de342e7cb0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm_custom = LightGBM()\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "for c in cat_cols:\n",
    "    X_train[c] = X_train[c].astype(\"category\")\n",
    "\n",
    "lgm_custom.fit(X_train, y_train, cat_cols=cat_cols, nfold=10, eval_train_metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcf9c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgm_custom.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcd41ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM RMSE: 1.4135615655958562\n",
      "LightGBM R²: 0.14585201528508407\n"
     ]
    }
   ],
   "source": [
    "mse_lgbm = mean_squared_error(y_test, y_pred)\n",
    "rmse_lgbm = mse_lgbm**0.5\n",
    "r2_lgbm = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"LightGBM RMSE:\", rmse_lgbm)\n",
    "print(\"LightGBM R²:\", r2_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff03c40",
   "metadata": {},
   "source": [
    "These results show LightGBM is **clearly learning more signal** than our linear regression baseline.\n",
    "\n",
    "- **RMSE: 1.414** on `log1p_DepDelayMinutes` (so the error is on the *log1p(minutes)* scale, not raw minutes).\n",
    "- **$R^2: 0.146$** means the model explains about **14.6% of the variance** in the test set.\n",
    "\n",
    "Compared to the baseline linear regression (RMSE ~$1.45$, $R^2$ ~$0.09$), LightGBM is an improvement: **lower error and higher explained variance**. That’s what we’d expect from boosted trees, since they can capture **non-linear effects** (e.g., weather impacts, airport/route effects, schedule interactions) and **feature interactions** that a linear model can’t."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933201cb",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "Now, we will train an XGBoost model using the same training and test sets. XGBoost is another powerful gradient-boosted decision tree model that often performs well on structured data tasks like this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44fc9550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] XGBoost - XGBoost initialized with parameters: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'learning_rate': 0.01, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'seed': 42, 'nthread': -1, 'tree_method': 'hist'}\n",
      "[INFO] XGBoost - Starting XGBoost training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] XGBoost - Training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 1.477385917645829\n",
      "XGBoost R²: 0.06697866641760086\n"
     ]
    }
   ],
   "source": [
    "xgbm = XGBoost(use_gpu=False, enable_categorical=True, max_depth=10, learning_rate=0.01)\n",
    "xgbm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    num_boost_round=2000,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose_eval=False,\n",
    " )\n",
    "\n",
    "y_pred_xgb = xgbm.predict(X_test)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = mse_xgb ** 0.5\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost RMSE:\", rmse_xgb)\n",
    "print(\"XGBoost R²:\", r2_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e90fdd",
   "metadata": {},
   "source": [
    "These results basically say the XGBoost model **isn’t beating our baseline yet**.\n",
    "\n",
    "- **RMSE: ~1.47** on `log1p_DepDelayMinutes` (so this is still on the *log1p(minutes)* scale, not raw minutes).\n",
    "- **$R^2: ~0.066$** means it explains about **6–7% of the variance** in the test set.\n",
    "\n",
    "So even though XGBoost *can* be a strong model for tabular data, right now it’s not finding much extra signal beyond what we already had (and it’s actually a bit worse than the linear regression baseline)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e941a121",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Finally, we will train a Random Forest model using the same training and test sets. Random Forest is an ensemble learning method that constructs multiple decision trees during training and outputs the mean prediction of the individual trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d7d229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] RandomForest - RandomForest (XGB-RF) initialized with parameters: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'eta': 1.0, 'num_parallel_tree': 200, 'subsample': 0.8, 'colsample_bytree': 0.8, 'max_depth': 8, 'seed': 42, 'nthread': -1, 'tree_method': 'hist'}\n",
      "[INFO] RandomForest - Starting RandomForest (XGB-RF) training...\n",
      "[INFO] RandomForest - Training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB-RF RMSE: 1.4801058119091801\n",
      "XGB-RF R²: 0.06354008569722558\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest(\n",
    "    n_trees=200,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    max_depth=8,\n",
    "    seed=42,\n",
    " )\n",
    "\n",
    "rf.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose_eval=False)\n",
    "y_pred_rf_like = rf.predict(X_test)\n",
    "\n",
    "mse_rf_like = mean_squared_error(y_test, y_pred_rf_like)\n",
    "rmse_rf_like = mse_rf_like ** 0.5\n",
    "r2_rf_like = r2_score(y_test, y_pred_rf_like)\n",
    "\n",
    "print(\"XGB-RF RMSE:\", rmse_rf_like)\n",
    "print(\"XGB-RF R²:\", r2_rf_like)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca368fec",
   "metadata": {},
   "source": [
    "There results show that Random Forest is not performing any better than XGBoost or even Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddfee84",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "\n",
    "Finally, we will train a CatBoost model using the same training and test sets. CatBoost is another gradient-boosted decision tree model that is particularly good at handling categorical features. It is very similar to LightGBM and XGBoost in terms of functionality, but it has some unique features that make it stand out, such as its ability to handle categorical features natively without the need for one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424f398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] CatBoost - CatBoost initialized with parameters: {'loss_function': 'RMSE', 'eval_metric': 'RMSE', 'random_seed': 42, 'verbose': False, 'iterations': 5000, 'learning_rate': 0.05, 'depth': 8}\n",
      "[INFO] CatBoost - Starting CatBoost training...\n",
      "[INFO] CatBoost - Training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost RMSE: 1.3976383434774091\n",
      "CatBoost R²: 0.16498692191196362\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "\n",
    "\n",
    "cb = CatBoost(\n",
    "    use_gpu=False,\n",
    "    iterations=5000,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    random_seed=42,\n",
    "    verbose=False,\n",
    " )\n",
    "\n",
    "cb.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=100)\n",
    "y_pred_cb = cb.predict(X_test)\n",
    "\n",
    "mse_cb = mean_squared_error(y_test, y_pred_cb)\n",
    "rmse_cb = mse_cb ** 0.5\n",
    "r2_cb = r2_score(y_test, y_pred_cb)\n",
    "\n",
    "print(\"CatBoost RMSE:\", rmse_cb)\n",
    "print(\"CatBoost R²:\", r2_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32769b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>1.397638</td>\n",
       "      <td>0.164987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.413562</td>\n",
       "      <td>0.145852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.447591</td>\n",
       "      <td>0.104233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.477386</td>\n",
       "      <td>0.066979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB-RF</td>\n",
       "      <td>1.480106</td>\n",
       "      <td>0.063540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      RMSE        R²\n",
       "0           CatBoost  1.397638  0.164987\n",
       "1           LightGBM  1.413562  0.145852\n",
       "2  Linear Regression  1.447591  0.104233\n",
       "3            XGBoost  1.477386  0.066979\n",
       "4             XGB-RF  1.480106  0.063540"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSES = {\n",
    "    \"Linear Regression\": rmse_lr,\n",
    "    \"LightGBM\": rmse_lgbm,\n",
    "    \"XGBoost\": rmse_xgb,\n",
    "    \"CatBoost\": rmse_cb,\n",
    "    \"XGB-RF\": rmse_rf_like,\n",
    "}\n",
    "R2S = {\n",
    "    \"Linear Regression\": r2_lr,\n",
    "    \"LightGBM\": r2_lgbm,\n",
    "    \"XGBoost\": r2_xgb,\n",
    "    \"CatBoost\": r2_cb,\n",
    "    \"XGB-RF\": r2_rf_like,\n",
    "}\n",
    "results_df = pd.DataFrame({\n",
    "    \"Model\": RMSES.keys(),\n",
    "    \"RMSE\": RMSES.values(),\n",
    "    \"R²\": R2S.values(),\n",
    "}).sort_values(by=\"RMSE\").reset_index(drop=True)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb661405",
   "metadata": {},
   "source": [
    "Given the results, CatBoost is performing the best. However, it is still not performing significantly better than LightGBM. We are expecting to use LightGBM given its faster training time compared to CatBoost in our actual deployment scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66191a72",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "The regression models were stable and generally good, but they plateaued at relatively low R² values (≈ 0.10–0.16), even with non-linear tree-based methods. This suggests that while there is predictive signal in the data, the exact magnitude of departure delay is noisy and partially driven by unobserved operational factors.\n",
    "\n",
    "To better align the modeling objective with the available signal, I will reframe the problem as a binary classification task: predicting whether a flight will experience a meaningful departure delay. This formulation reduces sensitivity to extreme outliers and focuses the model on learning stable delay patterns rather than precise delay values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "324fb3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DepDelayMinutes\n",
       "<=0      67709\n",
       "1–14     15005\n",
       "15–59    11342\n",
       ">=60      5940\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd = sample_df[\"DepDelayMinutes\"]\n",
    "\n",
    "bins = [-float(\"inf\"), 0, 14, 59, float(\"inf\")]\n",
    "labels = [\"<=0\", \"1–14\", \"15–59\", \">=60\"]\n",
    "display(pd.cut(dd, bins=bins, labels=labels).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ca59611",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df_class = FeatureEngineeringDepDelay(sample_df, classification=True).engineer_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f748d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"DepDelayCategory\"\n",
    "\n",
    "drop_cols = [c for c in [target_col, \"log1p_DepDelayMinutes\"] if c in engineered_df_class.columns]\n",
    "X_cls = engineered_df_class.drop(columns=drop_cols)\n",
    "y_cls = engineered_df_class[target_col].astype(int)\n",
    "\n",
    "cat_cols = X_cls.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "for c in cat_cols:\n",
    "    X_cls[c] = X_cls[c].astype(\"category\")\n",
    "\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
    "    X_cls, y_cls, test_size=0.2, random_state=42, stratify=y_cls\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "885618d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DepDelayCategory\n",
       "0    94164\n",
       "1     5832\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered_df_class.groupby('DepDelayCategory').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2618d",
   "metadata": {},
   "source": [
    "## LightGBM Classification\n",
    "\n",
    "Our LightGBM Regression model showed promising results, so we will adapt it for classification. We will define meaningful delay categories and train the model to predict these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0bddb6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] LightGBM - LightGBM model initialized with parameters: {'objective': 'multiclass', 'metric': 'multi_logloss', 'learning_rate': 0.05, 'num_leaves': 31, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'seed': 42, 'boosting_type': 'gbdt', 'verbose': -1, 'max_depth': -1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'min_data_in_leaf': 20, 'num_class': 3}\n",
      "[INFO] LightGBM - Starting model training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] LightGBM - Best iteration from CV: 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\ttrain's multi_logloss: 0.17523 + 0.000309315\tvalid's multi_logloss: 0.198068 + 0.00241909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] LightGBM - Model training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9422\n",
      "Confusion matrix:\n",
      " [[18834     0]\n",
      " [ 1156    10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     18834\n",
      "           1       1.00      0.01      0.02      1166\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.97      0.50      0.49     20000\n",
      "weighted avg       0.95      0.94      0.91     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm_cls = LightGBM(\n",
    "    classification=True,\n",
    "    objective=\"multiclass\",\n",
    "    metric=\"multi_logloss\",\n",
    "    num_class=3,\n",
    " )\n",
    "\n",
    "lgbm_cls.fit(X_train_cls, y_train_cls, cat_cols=cat_cols, nfold=10, eval_train_metric=True)\n",
    "y_pred_cls = lgbm_cls.predict(X_test_cls)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cls, y_pred_cls))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_cls, y_pred_cls))\n",
    "print(classification_report(y_test_cls, y_pred_cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43e6cd",
   "metadata": {},
   "source": [
    "### LightGBM (Multiclass) — Results\n",
    "\n",
    "**Overall**\n",
    "- **Accuracy:** `0.83415`\n",
    "- **Test set size:** `20000`\n",
    "\n",
    "**Class 0 vs Rest**\n",
    "```text\n",
    "                 Pred +      Pred -\n",
    "Actual + (class 0)   TP=16647    FN=8\n",
    "Actual - (not 0)     FP=3306     TN=39\n",
    "```\n",
    "\n",
    "**Class 1 vs Rest**\n",
    "```text\n",
    "                 Pred +      Pred -\n",
    "Actual + (class 1)   TP=27       FN=2152\n",
    "Actual - (not 1)     FP=7        TN=17814\n",
    "```\n",
    "\n",
    "**Class 2 vs Rest**\n",
    "```text\n",
    "                 Pred +      Pred -\n",
    "Actual + (class 2)   TP=9        FN=1157\n",
    "Actual - (not 2)     FP=4        TN=18830\n",
    "```\n",
    "\n",
    "\n",
    "**Notes**\n",
    "- The model performs very well on **Class 0** (recall ≈ `1.00`).\n",
    "- **Classes 1 and 2** have very low recall (≈ `0.01`), meaning the model rarely predicts these classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58367f",
   "metadata": {},
   "source": [
    "This is a known Problem in ML called Class Imbalance, where one class (here, Class 0) dominates the dataset, making it hard for the model to learn to predict the minority classes (Classes 1 and 2). To address this, we can try techniques like oversampling the minority classes, undersampling the majority class, or using class weights in the loss function to give more importance to the minority classes during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17aaacd",
   "metadata": {},
   "source": [
    "## Weighting Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdbe0dd",
   "metadata": {},
   "source": [
    "The first step to address class imbalance is to weight the classes inversely proportional to their frequencies. This way, the model will pay more attention to the minority classes during training. Let's compute the class weights and retrain the LightGBM model with these weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d8222486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(0): np.float64(0.5309703969202177),\n",
       " np.int64(1): np.float64(8.572224603514789)}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.unique(y_train_cls)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train_cls\n",
    ")\n",
    "\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae119cd",
   "metadata": {},
   "source": [
    "Now let's class weight to sample weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d0a5a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = y_train_cls.map(class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1952f",
   "metadata": {},
   "source": [
    "Now, we will retrain the LightGBM model using the computed class weights to see if it improves performance on the minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "305a3726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] LightGBM - LightGBM model initialized with parameters: {'objective': 'binary', 'metric': 'average_precision', 'learning_rate': 0.03, 'num_leaves': 63, 'feature_fraction': 0.85, 'bagging_fraction': 0.85, 'bagging_freq': 1, 'seed': 42, 'boosting_type': 'gbdt', 'verbose': -1, 'max_depth': -1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'min_data_in_leaf': 50}\n",
      "[INFO] LightGBM - Starting model training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] LightGBM - Best iteration from CV: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\ttrain's average_precision: 0.819008 + 0.00644439\tvalid's average_precision: 0.687325 + 0.01508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] LightGBM - Model training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68725\n",
      "Confusion matrix:\n",
      " [[13047  5787]\n",
      " [  468   698]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.69      0.81     18834\n",
      "           1       0.11      0.60      0.18      1166\n",
      "\n",
      "    accuracy                           0.69     20000\n",
      "   macro avg       0.54      0.65      0.49     20000\n",
      "weighted avg       0.92      0.69      0.77     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rng = 42\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"average_precision\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 63,\n",
    "    \"min_data_in_leaf\": 50,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"bagging_fraction\": 0.85,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"seed\": 42,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "lgbm_cls = LightGBM(\n",
    "    classification=True,\n",
    "    **params,\n",
    " )\n",
    "\n",
    "lgbm_cls.fit(\n",
    "    X_train_cls,\n",
    "    y_train_cls,\n",
    "    cat_cols=cat_cols,\n",
    "    sample_weight=sample_weights,\n",
    "    nfold=10,\n",
    "    eval_train_metric=True,\n",
    " )\n",
    "y_pred_cls = lgbm_cls.predict(X_test_cls)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cls, y_pred_cls))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_cls, y_pred_cls))\n",
    "print(classification_report(y_test_cls, y_pred_cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875f7b2",
   "metadata": {},
   "source": [
    "Our goal of this model is to catch class 1. In this case, recall of class 1 is 0.58, which mean the model is able to identify 58% of the actual class 1 instances. Precision of 0.14 of class 1 means that when the model predicts class 1, it is correct 14% of the time and wrong 86% of the time. It is really not what we want yet, but it is a good improvement from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c153eeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_Not_Delayed</th>\n",
       "      <th>Pred_Delayed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual_Not_Delayed</th>\n",
       "      <td>13179</td>\n",
       "      <td>5655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Delayed</th>\n",
       "      <td>498</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Pred_Not_Delayed  Pred_Delayed\n",
       "Actual_Not_Delayed             13179          5655\n",
       "Actual_Delayed                   498           668"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_Not_Delayed</th>\n",
       "      <th>Pred_Delayed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual_Not_Delayed</th>\n",
       "      <td>0.65895</td>\n",
       "      <td>0.28275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Delayed</th>\n",
       "      <td>0.02490</td>\n",
       "      <td>0.03340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Pred_Not_Delayed  Pred_Delayed\n",
       "Actual_Not_Delayed           0.65895       0.28275\n",
       "Actual_Delayed               0.02490       0.03340"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_test_cls, y_pred_cls)\n",
    "\n",
    "n_classes = int(conf.shape[0])\n",
    "if n_classes == 2:\n",
    "    class_labels = [\"Not_Delayed\", \"Delayed\"]\n",
    "else:\n",
    "    class_labels = [f\"Class_{i}\" for i in range(n_classes)]\n",
    "\n",
    "conf_df = pd.DataFrame(\n",
    "    conf,\n",
    "    index=[f\"Actual_{c}\" for c in class_labels],\n",
    "    columns=[f\"Pred_{c}\" for c in class_labels],\n",
    ")\n",
    "\n",
    "display(conf_df)\n",
    "\n",
    "conf_df /conf.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f644ef90",
   "metadata": {},
   "source": [
    "## CatBoost Classification\n",
    "\n",
    "Now, we will retrain the CatBoost model using the computed class weights to see if it improves performance on the minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46349d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] CatBoost - CatBoost initialized with parameters: {'loss_function': 'Logloss', 'eval_metric': 'AUC', 'random_seed': 42, 'verbose': False, 'iterations': 500, 'learning_rate': 0.05, 'depth': 7, 'auto_class_weights': 'Balanced'}\n",
      "[INFO] CatBoost - Starting CatBoost training...\n",
      "[INFO] CatBoost - Training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73405\n",
      "Confusion matrix:\n",
      " [[13823  5011]\n",
      " [  308   858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.84     18834\n",
      "           1       0.15      0.74      0.24      1166\n",
      "\n",
      "    accuracy                           0.73     20000\n",
      "   macro avg       0.56      0.73      0.54     20000\n",
      "weighted avg       0.93      0.73      0.80     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"iterations\": 500,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 7,\n",
    "    \"auto_class_weights\": \"Balanced\", \n",
    "    \"verbose\": False,\n",
    "}\n",
    "\n",
    "cb_cls = CatBoost(classification=True, **params)\n",
    "\n",
    "cb_cls.fit(\n",
    "    X_train_cls,\n",
    "    y_train_cls,\n",
    "    nfold=1,\n",
    "    early_stopping_rounds=100)\n",
    "\n",
    "y_pred = cb_cls.predict(X_test_cls)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cls, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_cls, y_pred))\n",
    "print(classification_report(y_test_cls, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a56b4b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97010821, 0.02989179],\n",
       "       [0.97088185, 0.02911815],\n",
       "       [0.71819919, 0.28180081],\n",
       "       ...,\n",
       "       [0.66313351, 0.33686649],\n",
       "       [0.98325129, 0.01674871],\n",
       "       [0.399377  , 0.600623  ]], shape=(20000, 2))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities instead of hard class predictions\n",
    "y_pred_proba = cb_cls.predict(X_test_cls, prediction_type=\"Probability\")\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae686a45",
   "metadata": {},
   "source": [
    "Let say we want to predict a flight that going from Baltimore to Denver on January 12 (in 6 days). We will need to call the FlightWeather class wrapper in order to get the weather and flight data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2fc7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightWeather = FlightWeather(flight_num=\"UA 2012\", flight_date=\"2026-01-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "537579df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching weather data from: https://api.open-meteo.com/v1/forecast\n",
      "Successfully fetched data for 2 airport(s).\n"
     ]
    }
   ],
   "source": [
    "flight_df = flightWeather.get_full_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "06883950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sample_df.drop(columns=[\"DepDelayMinutes\", 'arr_date']).columns) == set(Flight_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72908d3f",
   "metadata": {},
   "source": [
    "In my feature engineering class, I save .pkl files for stats about airlines, airports, and routes. When I predict a new feature, I can set type = \"new\", and the files will be loaded and attached to the new flight. When I load these .pkl files, I make sure to handle any unknown categories by filling in missing values with statistics for an \"__UNKNOWN__\" category. This way, if the flight data includes an airline, airport, or route that wasn't seen during training, the model can still make a reasonable prediction using the average statistics for unknown categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7febf822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data/airline_stats.pkl', 'rb') as f:\n",
    "    airline_stats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f3e00a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IATA_Code_Operating_Airline</th>\n",
       "      <th>Distance</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>dep_snowfall</th>\n",
       "      <th>dep_rain</th>\n",
       "      <th>dep_precipitation</th>\n",
       "      <th>dep_wind_speed_10m</th>\n",
       "      <th>dep_wind_gusts_10m</th>\n",
       "      <th>dep_cloud_cover_low</th>\n",
       "      <th>dep_cloud_cover</th>\n",
       "      <th>dep_temperature_2m</th>\n",
       "      <th>dep_apparent_temperature</th>\n",
       "      <th>dep_surface_pressure</th>\n",
       "      <th>dep_relative_humidity_2m</th>\n",
       "      <th>dep_pressure_msl</th>\n",
       "      <th>arr_snowfall</th>\n",
       "      <th>arr_rain</th>\n",
       "      <th>arr_precipitation</th>\n",
       "      <th>arr_wind_speed_10m</th>\n",
       "      <th>arr_wind_gusts_10m</th>\n",
       "      <th>arr_cloud_cover_low</th>\n",
       "      <th>arr_cloud_cover</th>\n",
       "      <th>arr_temperature_2m</th>\n",
       "      <th>arr_apparent_temperature</th>\n",
       "      <th>arr_surface_pressure</th>\n",
       "      <th>arr_relative_humidity_2m</th>\n",
       "      <th>arr_pressure_msl</th>\n",
       "      <th>departure_hour</th>\n",
       "      <th>departure_day</th>\n",
       "      <th>departure_month</th>\n",
       "      <th>departure_weekday</th>\n",
       "      <th>departure_is_weekend</th>\n",
       "      <th>departure_is_peak_hour</th>\n",
       "      <th>arrival_hour</th>\n",
       "      <th>arrival_day</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_weekday</th>\n",
       "      <th>arrival_is_weekend</th>\n",
       "      <th>arrival_is_peak_hour</th>\n",
       "      <th>average_delay</th>\n",
       "      <th>delay_stddev</th>\n",
       "      <th>on_time_rate</th>\n",
       "      <th>is_high_dep_congestion</th>\n",
       "      <th>is_high_arr_congestion</th>\n",
       "      <th>dep_congestion_bucket</th>\n",
       "      <th>arr_congestion_bucket</th>\n",
       "      <th>route</th>\n",
       "      <th>average_route_delay</th>\n",
       "      <th>delay_route_stddev</th>\n",
       "      <th>dep_congestion_x_precipitation</th>\n",
       "      <th>dep_congestion_x_wind_gusts</th>\n",
       "      <th>dep_congestion_x_snowfall</th>\n",
       "      <th>arr_congestion_x_precipitation</th>\n",
       "      <th>arr_congestion_x_wind_gusts</th>\n",
       "      <th>arr_congestion_x_snowfall</th>\n",
       "      <th>distance_x_dep_precipitation</th>\n",
       "      <th>distance_x_dep_wind_gusts_10m</th>\n",
       "      <th>distance_x_dep_snowfall</th>\n",
       "      <th>distance_x_arr_precipitation</th>\n",
       "      <th>distance_x_arr_wind_gusts_10m</th>\n",
       "      <th>distance_x_arr_snowfall</th>\n",
       "      <th>temperature_delta</th>\n",
       "      <th>abs_temperature_delta</th>\n",
       "      <th>apparent_temperature_delta</th>\n",
       "      <th>abs_apparent_temperature_delta</th>\n",
       "      <th>humidity_delta</th>\n",
       "      <th>abs_humidity_delta</th>\n",
       "      <th>pressure_delta</th>\n",
       "      <th>abs_pressure_delta</th>\n",
       "      <th>cloud_cover_delta</th>\n",
       "      <th>abs_cloud_cover_delta</th>\n",
       "      <th>dep_gust_factor</th>\n",
       "      <th>arr_gust_factor</th>\n",
       "      <th>congestion_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UA</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.055355</td>\n",
       "      <td>25.559999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.111</td>\n",
       "      <td>-0.563633</td>\n",
       "      <td>1020.597168</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1026.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.570515</td>\n",
       "      <td>16.559999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.2005</td>\n",
       "      <td>-3.277061</td>\n",
       "      <td>839.25769</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1024.199951</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.128977</td>\n",
       "      <td>55.574644</td>\n",
       "      <td>0.792409</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>BWI-DEN</td>\n",
       "      <td>12.081081</td>\n",
       "      <td>16.535111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>638.999987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1838.159941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38109.959204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24690.959204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9105</td>\n",
       "      <td>3.9105</td>\n",
       "      <td>2.713428</td>\n",
       "      <td>2.713428</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.300049</td>\n",
       "      <td>2.300049</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.591992</td>\n",
       "      <td>1.431224</td>\n",
       "      <td>-86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IATA_Code_Operating_Airline  Distance  CRSElapsedTime  dep_snowfall  \\\n",
       "0                          UA    1491.0           220.0           0.0   \n",
       "\n",
       "   dep_rain  dep_precipitation  dep_wind_speed_10m  dep_wind_gusts_10m  \\\n",
       "0       0.0                0.0           16.055355           25.559999   \n",
       "\n",
       "   dep_cloud_cover_low  dep_cloud_cover  dep_temperature_2m  \\\n",
       "0                  0.0              2.0               5.111   \n",
       "\n",
       "   dep_apparent_temperature  dep_surface_pressure  dep_relative_humidity_2m  \\\n",
       "0                 -0.563633           1020.597168                      30.0   \n",
       "\n",
       "   dep_pressure_msl  arr_snowfall  arr_rain  arr_precipitation  \\\n",
       "0            1026.5           0.0       0.0                0.0   \n",
       "\n",
       "   arr_wind_speed_10m  arr_wind_gusts_10m  arr_cloud_cover_low  \\\n",
       "0           11.570515           16.559999                  0.0   \n",
       "\n",
       "   arr_cloud_cover  arr_temperature_2m  arr_apparent_temperature  \\\n",
       "0              8.0              1.2005                 -3.277061   \n",
       "\n",
       "   arr_surface_pressure  arr_relative_humidity_2m  arr_pressure_msl  \\\n",
       "0             839.25769                      63.0       1024.199951   \n",
       "\n",
       "   departure_hour  departure_day  departure_month  departure_weekday  \\\n",
       "0              16             12                1                  0   \n",
       "\n",
       "   departure_is_weekend  departure_is_peak_hour  arrival_hour  arrival_day  \\\n",
       "0                     0                       1            18           12   \n",
       "\n",
       "   arrival_month  arrival_weekday  arrival_is_weekend  arrival_is_peak_hour  \\\n",
       "0              1                0                   0                     1   \n",
       "\n",
       "   average_delay  delay_stddev  on_time_rate  is_high_dep_congestion  \\\n",
       "0      15.128977     55.574644      0.792409                       0   \n",
       "\n",
       "   is_high_arr_congestion  dep_congestion_bucket  arr_congestion_bucket  \\\n",
       "0                       1                      1                      3   \n",
       "\n",
       "     route  average_route_delay  delay_route_stddev  \\\n",
       "0  BWI-DEN            12.081081           16.535111   \n",
       "\n",
       "   dep_congestion_x_precipitation  dep_congestion_x_wind_gusts  \\\n",
       "0                             0.0                   638.999987   \n",
       "\n",
       "   dep_congestion_x_snowfall  arr_congestion_x_precipitation  \\\n",
       "0                        0.0                             0.0   \n",
       "\n",
       "   arr_congestion_x_wind_gusts  arr_congestion_x_snowfall  \\\n",
       "0                  1838.159941                        0.0   \n",
       "\n",
       "   distance_x_dep_precipitation  distance_x_dep_wind_gusts_10m  \\\n",
       "0                           0.0                   38109.959204   \n",
       "\n",
       "   distance_x_dep_snowfall  distance_x_arr_precipitation  \\\n",
       "0                      0.0                           0.0   \n",
       "\n",
       "   distance_x_arr_wind_gusts_10m  distance_x_arr_snowfall  temperature_delta  \\\n",
       "0                   24690.959204                      0.0             3.9105   \n",
       "\n",
       "   abs_temperature_delta  apparent_temperature_delta  \\\n",
       "0                 3.9105                    2.713428   \n",
       "\n",
       "   abs_apparent_temperature_delta  humidity_delta  abs_humidity_delta  \\\n",
       "0                        2.713428           -33.0                33.0   \n",
       "\n",
       "   pressure_delta  abs_pressure_delta  cloud_cover_delta  \\\n",
       "0        2.300049            2.300049               -6.0   \n",
       "\n",
       "   abs_cloud_cover_delta  dep_gust_factor  arr_gust_factor  congestion_delta  \n",
       "0                    6.0         1.591992         1.431224               -86  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df_engineered = FeatureEngineeringDepDelay(flight_df, type=\"new\").engineer_features()\n",
    "flight_df_engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "53a5c031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_delay    15.128977\n",
       "delay_stddev     55.574644\n",
       "on_time_rate      0.792409\n",
       "Name: UA, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_stats.loc['UA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8edc0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTW_DEN_pred = cb_cls.predict(flight_df_engineered, prediction_type=\"Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "83ad7cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74138222, 0.25861778]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTW_DEN_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2221dc0b",
   "metadata": {},
   "source": [
    "Based On this results, the model predicted that the flight has a 75% chance of being in class 0 (on time), a 20% chance of being in class 1 (60 minutes delayed). Is not that amazing?\n",
    "\n",
    "We can now save the model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "195d7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/catboost_sample_model.pkl', 'wb') as f:\n",
    "    pickle.dump(cb_cls, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea48b1a",
   "metadata": {},
   "source": [
    "Then Use it again later by loading it from the .pkl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "751bd0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74138222, 0.25861778]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/catboost_sample_model.pkl', 'rb') as f:\n",
    "    cb_loaded = pickle.load(f)\n",
    "cb_loaded.predict(flight_df_engineered, prediction_type=\"Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d024a833",
   "metadata": {},
   "source": [
    "## Training on GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d93d85e",
   "metadata": {},
   "source": [
    "We already trained the LightGBM and CatBoost models on CPU, and we showed that CatBoost performed slightly better than LightGBM for our classification task. However, our model got low precision for class 1, which means that out of all delayed flights predicted by the model, only a small fraction were actually delayed. This is not ideal for our use case, as we want to minimize false positives (i.e., predicting a flight will be delayed when it is not). Maybe a better solution would be to train the model on GPUs, which can handle larger datasets and more complex models more efficiently than CPUs. By leveraging the parallel processing capabilities of GPUs, we can potentially improve the model's performance and achieve better precision for class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet('./data/full_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5288602",
   "metadata": {},
   "source": [
    "We need to calculate stats on the training data only, so we will split the full dataset into training and test sets before calculating the stats. This way, we can ensure that the stats are not biased by the test data, and we can get a more accurate estimate of the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2641aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cls, test_cls = train_test_split(\n",
    "    full_df, test_size=0.2, random_state=42, shuffle=True\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "67302910",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df_class_train = FeatureEngineeringDepDelay(train_cls, classification=True).engineer_features()\n",
    "engineered_df_class_test = FeatureEngineeringDepDelay(test_cls, classification=True, type=\"new\").engineer_features(is_test=True)\n",
    "\n",
    "target_col = \"DepDelayCategory\"\n",
    "\n",
    "X_train_cls = engineered_df_class_train.drop(columns=[target_col])\n",
    "y_train_cls = engineered_df_class_train[target_col].astype(int)\n",
    "\n",
    "X_test_cls = engineered_df_class_test.drop(columns=[target_col])\n",
    "y_test_cls = engineered_df_class_test[target_col].astype(int)\n",
    "\n",
    "cat_cols = X_train_cls.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "for c in cat_cols:\n",
    "    X_train_cls[c] = X_train_cls[c].astype(\"category\")\n",
    "    X_test_cls[c] = X_test_cls[c].astype(\"category\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf52451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] CatBoost - CatBoost initialized with parameters: {'loss_function': 'Logloss', 'eval_metric': 'AUC', 'random_seed': 42, 'verbose': 200, 'task_type': 'GPU', 'iterations': 5000, 'learning_rate': 0.05, 'depth': 7, 'auto_class_weights': 'Balanced', 'devices': '0:1'}\n",
      "[INFO] CatBoost - Running 5-fold CV to select iterations...\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "catboost/cuda/cuda_lib/cuda_base.h:281: CUDA error 35: CUDA driver version is insufficient for CUDA runtime version",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatBoostError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m      9\u001b[39m params = {\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mLogloss\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33meval_metric\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mAUC\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdevices\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m0:1\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     20\u001b[39m }\n\u001b[32m     24\u001b[39m cb_gpu_cls = CatBoost(use_gpu=\u001b[38;5;28;01mTrue\u001b[39;00m, classification=\u001b[38;5;28;01mTrue\u001b[39;00m, **params)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mcb_gpu_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnfold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m y_pred_gpu = cb_gpu_cls.predict(X_test_cls)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAccuracy:\u001b[39m\u001b[33m\"\u001b[39m, accuracy_score(y_test_cls, y_pred_gpu))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Personal_Things\\My Website\\My website HTML\\backend\\supplychainAPI\\models\\src\\catboost.py:24\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(self, X, y, eval_set, nfold, cv_seed, cv_shuffle, early_stopping_rounds, **kwargs)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     15\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     **params: Any,\n\u001b[32m     19\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     20\u001b[39m     default_params: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = {\n\u001b[32m     21\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33meval_metric\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrandom_seed\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m42\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     25\u001b[39m     }\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_gpu:\n\u001b[32m     28\u001b[39m         default_params.update({\u001b[33m\"\u001b[39m\u001b[33mtask_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mGPU\u001b[39m\u001b[33m\"\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\catboost\\core.py:6980\u001b[39m, in \u001b[36mcv\u001b[39m\u001b[34m(pool, params, dtrain, iterations, num_boost_round, fold_count, nfold, inverted, partition_random_seed, seed, shuffle, logging_level, stratified, as_pandas, metric_period, verbose, verbose_eval, plot, plot_file, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, metric_update_interval, folds, type, return_models, log_cout, log_cerr)\u001b[39m\n\u001b[32m   6978\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m log_fixup(log_cout, log_cerr), plot_wrapper(plot, plot_file=plot_file, plot_title=\u001b[33m'\u001b[39m\u001b[33mCross-validation plot\u001b[39m\u001b[33m'\u001b[39m, train_dirs=plot_dirs):\n\u001b[32m   6979\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_models:\n\u001b[32m-> \u001b[39m\u001b[32m6980\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6981\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6982\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6983\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfold_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6984\u001b[39m \u001b[43m            \u001b[49m\u001b[43minverted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6985\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpartition_random_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6986\u001b[39m \u001b[43m            \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6987\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstratified\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6988\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetric_update_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6989\u001b[39m \u001b[43m            \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6990\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6991\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   6992\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreturn_models\u001b[49m\n\u001b[32m   6993\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6994\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6995\u001b[39m         results, cv_models = _cv(\n\u001b[32m   6996\u001b[39m             params,\n\u001b[32m   6997\u001b[39m             pool,\n\u001b[32m   (...)\u001b[39m\u001b[32m   7007\u001b[39m             return_models\n\u001b[32m   7008\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5880\u001b[39m, in \u001b[36m_catboost._cv\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5912\u001b[39m, in \u001b[36m_catboost._cv\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCatBoostError\u001b[39m: catboost/cuda/cuda_lib/cuda_base.h:281: CUDA error 35: CUDA driver version is insufficient for CUDA runtime version"
     ]
    }
   ],
   "source": [
    "n_classes = int(pd.Series(y_train_cls).nunique())\n",
    "is_binary = n_classes == 2\n",
    "\n",
    "params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"iterations\": 5000,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 7,\n",
    "    \"random_seed\": 42,\n",
    "    \"auto_class_weights\": \"Balanced\",\n",
    "    \"verbose\": 200,\n",
    "    \"task_type\": \"GPU\",\n",
    "    \"devices\": \"0:1\", \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "cb_gpu_cls = CatBoost(use_gpu=True, classification=True, **params)\n",
    "cb_gpu_cls.fit(\n",
    "    X_train_cls,\n",
    "    y_train_cls,\n",
    "    nfold=5,\n",
    "    early_stopping_rounds=200,\n",
    " )\n",
    "\n",
    "y_pred_gpu = cb_gpu_cls.predict(X_test_cls)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cls, y_pred_gpu))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_cls, y_pred_gpu))\n",
    "print(classification_report(y_test_cls, y_pred_gpu))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
